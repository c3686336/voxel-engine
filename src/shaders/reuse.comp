#version 450 core
#extension GL_ARB_shading_language_include : require

#define N_SAMPLES 32

const int N_NEIGHBORS = 3;
const int TAXI_RADIUS = 128;

layout(local_size_x = 8, local_size_y = 4, local_size_z = 1) in;

layout(rgba32f, binding = 1) writeonly uniform image2D out_img;

layout(location = 1) uniform vec3 camera_pos;
layout(location = 2) uniform vec3 camera_dir;
layout(location = 5) uniform vec3 camera_right;
layout(location = 4) uniform vec3 camera_up;
layout(location = 6) uniform float bias_amt;
layout(location = 8) uniform uint n_models;
layout(location = 9) uniform vec4 m_albedo;
layout(location = 10) uniform float m_metallicity;
layout(location = 11) uniform float m_roughness;
layout(location = 12) uniform samplerCube skybox;
layout(location = 13) uniform float additional_seed;
layout(location = 15) uniform int width;
layout(location = 16) uniform int height;
layout(location = 17) uniform bool is_first_frame;
layout(location = 20) uniform bool t_reuse;

const int M = N_NEIGHBORS + 1 + (is_first_frame ? 0 : 1);

#include "common.comp"

#define PHAT phat1

void main() {
    // TODO: Account for camera and object movement

    Sample current = pixel_sample[global_index];

    if (current.path[1].w == 0.0) {
        imageStore(out_img, tcoord, texture(skybox, current.path[1].xyz)); // 0 bounce
        prev_pixel_sample[global_index] = current;
        return;
    }

    float mis_canonical = 0.0;
    Reservoir r = new_reservoir();

    float p11 = current.sample_phat;

    // Spatial reuse
    // TODO: parallelize this
    for (int i = 0; i < N_NEIGHBORS; i++) {
        // Shift the sampling domain a bit if the pixel is too close to the border
        uint neighbor_x_min = max(int(gl_GlobalInvocationID.x) - TAXI_RADIUS, 0);
        uint neighbor_x_max = min(neighbor_x_min + 2 * TAXI_RADIUS, width - 1);
        neighbor_x_min = neighbor_x_max - 2 * TAXI_RADIUS;

        uint neighbor_y_min = max(int(gl_GlobalInvocationID.y) - TAXI_RADIUS, 0);
        uint neighbor_y_max = min(neighbor_y_min + 2 * TAXI_RADIUS, height - 1);
        neighbor_y_min = neighbor_y_max - 2 * TAXI_RADIUS;

        uvec2 offset = uvec2(randv2() * 2.0 * float(TAXI_RADIUS));

        uvec2 sample_pos = uvec2(neighbor_x_min, neighbor_y_min) + offset;
        uint sample_index = sample_pos.y * width + sample_pos.x;

        Sample neighbor = pixel_sample[sample_index];

        // Neighbor rejection
        if (neighbor.path[1].w == 0.0 || dot(neighbor.normal[0], current.normal[0]) < 0.5 || isnan(neighbor.W)) {
            continue;
        }

        float p1x = PHAT(
                current.path[1],
                current.normal[0],
                current.view_dir[0],
                -neighbor.view_dir[1],
                current.albedo[0],
                current.roughness[0],
                current.metallicity[0]
            ); // phat on current domain, towards neighbor's sample

        float pix = neighbor.sample_phat;

        float pi1 = PHAT(
                neighbor.path[1],
                neighbor.normal[0],
                neighbor.view_dir[0],
                -current.view_dir[1],
                neighbor.albedo[0],
                neighbor.roughness[0],
                neighbor.metallicity[0]
            ); // phat on neighbor's domain, towards current sample

        float m = pix / (p1x / float(M - 1) + pix); // pairwise mis
        float w = m * p1x * neighbor.W;

        // Shift
        vec3 neighbor_viewdir = neighbor.view_dir[1];
        vec4 neighbor_path = neighbor.path[2];
        neighbor = current;
        neighbor.view_dir[1] = neighbor_viewdir;
        neighbor.path[2] = neighbor_path;

        updateR(r, neighbor, w);

        mis_canonical += p11 / (p11 / float(M - 1) + pi1) / float(M - 1);
    }

    // Temporal reuse
    Sample temporal = prev_pixel_sample[global_index];
    if (!is_first_frame && temporal.path[1].w != 0.0 && t_reuse) {
        float p1x = PHAT(
                current.path[1],
                current.normal[0],
                current.view_dir[0],
                -temporal.view_dir[1].xyz,
                current.albedo[0],
                current.roughness[0],
                current.metallicity[0]
            ); // phat on current domain, towards previous sample

        float pix = temporal.sample_phat;

        float pi1 = PHAT(
                temporal.path[1],
                temporal.normal[0],
                temporal.view_dir[0],
                -current.view_dir[1].xyz,
                temporal.albedo[0],
                temporal.roughness[0],
                temporal.metallicity[0]
            ); // phat on previous domain, towards current sample

        float m = pix / (p1x / float(M - 1) + pix) / float(M - 1); // pairwise mis
        float w = m * p1x * temporal.W;

        vec3 temporal_viewdir = temporal.view_dir[1];
        vec4 temporal_path = temporal.path[2];
        temporal = current;
        temporal.view_dir[1] = temporal_viewdir;
        temporal.path[2] = temporal_path;

        updateR(r, temporal, w);

        mis_canonical += p11 / (p11 / float(M - 1) + pi1) / float(M - 1);
    }

    mis_canonical /= float(M - 1);

    updateR(r, current, mis_canonical * p11 * current.W);

    Sample result = r.sample_chosen;
    result.W = r.total_weight / result.sample_phat;

    Sample s = result;
    prev_pixel_sample[global_index] = result;

    if (s.path[1].w == 0.0) {} else {
        bool shadow_result = trace_shadow(
                s.path[1] + bias_amt * vec4(s.normal[0], 0.0), vec4(-s.view_dir[1], 0.0)
            );

        vec3 frag_color =
            shadow_result ?
            vec3(0.0) :
            s.W * texture(skybox, s.path[2].xyz).xyz * brdf(
                    s.normal[0],
                    s.view_dir[0],
                    -s.view_dir[1],
                    s.albedo[0],
                    s.roughness[0],
                    s.metallicity[0]
                ); // Can't use sample_phat here

        imageStore(out_img, tcoord, vec4(frag_color, 1.0));
    }
}
